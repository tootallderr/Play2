# LLM Media Player & Library Manager
## Overview
This project is an AI-powered media center that combines the functionality of a media player with intelligent, personality-based captions and smart playback features. It automatically monitors your media libraries, processes subtitles using LLMs into various "modes," and delivers a deeply customized watching experience.
## Features
* âœ… Auto-scans specified folders for new media
* âœ… Organizes TV shows, movies, and videos
* âœ… Retrieves metadata, posters, and descriptions (via TMDB API)
* âœ… Detects available subtitles (SRT/VTT) or extracts from video
* âœ… Caches everything locally for speed
* âœ… Transforms captions with real-time or batch processing using LLMs

* âœ… Full monitoring of libraries
* âœ… Comprehensive feature set
* âœ… Real-time or cached caption transformation using LLMs
* âœ… Personality-driven â€œmodesâ€
* âœ… TiVo-style playback tools
* âœ… Auto-discovery, metadata fetching, and UI interaction

Hereâ€™s your full markdown file for use in **VS Code Agent Mode**, or just standard project bootstrapping.

---

```markdown
# ğŸ¥ LLM Media Player & Library Manager

An AI-powered media center like Plex â€” but with a twist: intelligent, personality-based captions and smart playback features. Automatically monitors your media libraries, processes subtitles using LLMs into â€œmodesâ€ like *Weed Mode*, *Theo Von Commentary*, or *Fact-Checker Mode*, and delivers a deeply customized watching experience.

---

## ğŸ§© Features

### ğŸ—‚ Media Library Management
- Auto-scans specified folders for new media
- Organizes TV shows, movies, and videos
- Retrieves metadata, posters, and descriptions (via TMDB API)
- Detects available subtitles (SRT/VTT) or extracts from video
- Caches everything locally for speed

### ğŸ­ LLM Caption Modes
Transform captions with real-time or batch processing using LLMs:

| Mode             | Description |
|------------------|-------------|
| ğŸ¥¦ **Weed Mode** | Converts captions to chill, slangy, stoner-friendly tone |
| ğŸ£ **Theo Von** | Retells scenes in Theoâ€™s absurd Southern metaphors |
| ğŸ¥© **Joey Diaz** | Explosive Bronx-style storytelling about each scene |
| ğŸ§  **Fact-Check** | Adds quick fact-checks to statements in captions |
| ğŸ§¾ **Trivia Mode** | Sprinkles in fun facts about people/places/topics |

### â¯ï¸ TiVo-style Playback
- Smart Skip (intros, ads, recaps)
- Resume from last watched position
- Instant replay ("go back 15s")
- Auto-chaptering for long media
- Voice assistant support (coming soon)

---

## ğŸ› ï¸ Tech Stack

- **Frontend**: Next.js + TailwindCSS + video.js
- **Backend**: FastAPI (Python)
- **LLM**: OpenAI GPT-4, Claude, or local LLM (via API)
- **Subtitles**: `pysrt`, `ffmpeg`, `webvtt`
- **Database**: SQLite / PostgreSQL
- **File Watcher**: `watchdog` (Python)
- **Media Info**: `ffprobe`, `tmdbsimple`

---

## ğŸ“ Project Structure

```

llm-media-player/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api/                # FastAPI endpoints
â”‚   â”œâ”€â”€ caption\_modes/      # Prompt templates + transformation logic
â”‚   â”œâ”€â”€ media\_scanner/      # Directory monitoring, metadata fetching
â”‚   â”œâ”€â”€ subtitle\_engine/    # Parser, LLM integration, caching
â”‚   â””â”€â”€ main.py             # Entrypoint
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ components/         # React/Next.js UI
â”‚   â”œâ”€â”€ pages/              # Video player, library views
â”‚   â””â”€â”€ App.tsx
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ cache/              # Transformed subtitles
â”‚   â””â”€â”€ media\_library.json  # Scanned library data
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â””â”€â”€ README.md

````

---

## ğŸ“¦ Setup Instructions (VS Code Agent Mode Ready)

### 1. Prerequisites

- Python 3.9+
- Node.js 18+
- `ffmpeg` and `ffprobe` installed
- OpenAI API key (or other LLM provider)
- VS Code + Dev Container support

---

### 2. Clone + Start in Dev Container

```bash
git clone https://github.com/yourname/llm-media-player
cd llm-media-player
code .  # Open in VS Code
````

Use **"Reopen in Container"** if prompted.

---

### 3. Create `.env` File

```env
OPENAI_API_KEY=your_openai_key_here
TMDB_API_KEY=your_tmdb_key
CAPTION_MODE_CACHE_DIR=./data/cache
WATCHED_DIRS=/mnt/media/movies,/mnt/media/tvshows
LLM_MODEL=gpt-4
```

---

### 4. Install Dependencies

**Backend:**

```bash
cd backend
pip install -r requirements.txt
```

**Frontend:**

```bash
cd frontend
npm install
```

---

### 5. Run the App

Open 2 terminals:

**Backend:**

```bash
cd backend
uvicorn main:app --reload
```

**Frontend:**

```bash
cd frontend
npm run dev
```

Visit `http://localhost:3000`

---

## ğŸ” How Caption Transformation Works

1. Detect subtitle file (or extract with ffmpeg)
2. Split into blocks (2â€“5s)
3. Feed blocks into LLM with selected mode prompt
4. Rebuild subtitle file (resynced or original timestamps)
5. Cache results and serve via UI

---

## âœ¨ Sample Caption Prompts

**Weed Mode Prompt:**

```text
Make this caption sound like a stoner is talking. Keep it chill, use slang, and remove complex words. Think Cheech and Chong watching a movie.
```

**Theo Von Prompt:**

```text
Retell this scene like Theo Von. Use southern metaphors, absurd analogies, weird personal stories. Stay funny, but vaguely make sense.
```

**Fact-Check Prompt:**

```text
For each sentence, add a short correction or confirmation of any claim. If something is historically or factually questionable, briefly clarify.
```

---

## ğŸ§  Caption Mode Creation Guide

To add your own mode:

1. Create a new file in `backend/caption_modes/your_mode.py`
2. Define:

```python
def transform_caption(text: str) -> str:
    prompt = f"...your instruction here..."
    return call_llm(prompt + text)
```

3. Register it in `main.py`

---

## ğŸ“ˆ Planned Features

* [ ] Auto-download subtitles if missing
* [ ] Narrator Audio Mode (AI voiceover of captions)
* [ ] Multi-user support w/ watch history
* [ ] Voice Commands: â€œSummarize scene in Joey Diaz modeâ€
* [ ] Companion mobile app

---

## ğŸ§ª Developer Tips

* Use `watchdog` to rescan media folders automatically.
* Use `ffprobe` to get media metadata without loading the video.
* Cache caption mode results with timestamped hash keys.
* Use `websockets` to push progress updates to frontend in real time.

---

## ğŸ¤ Acknowledgments

* Inspired by: Plex, Jellyfin, TiVo, Cheech & Chong, Theo Von, Joey Diaz
* Powered by: OpenAI, Python, Next.js, ffmpeg
* Made for: People who want their media player to have a personality.

---

## ğŸ“œ License

MIT License. Modify, remix, or go wild with it.

```

---
